{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7367\n",
      "7367\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "def load_livedoor_news_corpus():\n",
    "    category = {\n",
    "        'dokujo-tsushin': 1,\n",
    "        'it-life-hack':2,\n",
    "        'kaden-channel': 3,\n",
    "        'livedoor-homme': 4,\n",
    "        'movie-enter': 5,\n",
    "        'peachy': 6,\n",
    "        'smax': 7,\n",
    "        'sports-watch': 8,\n",
    "        'topic-news':9\n",
    "    }\n",
    "    docs  = []\n",
    "    labels = []\n",
    "\n",
    "    for c_name, c_id in category.items():\n",
    "        files = glob.glob(\"./text/{c_name}/{c_name}*.txt\".format(c_name=c_name))\n",
    "\n",
    "        text = ''\n",
    "        for file in files:\n",
    "            with open(file, 'r') as f:\n",
    "                lines = f.read().splitlines() \n",
    "\n",
    "                url = lines[0]\n",
    "                datetime = lines[1]\n",
    "                subject = lines[2]\n",
    "                body = \"\\n\".join(lines[3:])\n",
    "                text = subject + \"\\n\" + body\n",
    "\n",
    "            docs.append(text)\n",
    "            labels.append(c_id)\n",
    "\n",
    "    return docs, labels\n",
    "\n",
    "docs, labels = load_livedoor_news_corpus()\n",
    "print(len(docs))   # 7367\n",
    "print(len(labels)) # 7367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ナイナイ矢部浩之の卒業文集がネット上で話題に\n",
      "2月29日、日本テレビの「1番ソングSHOW！」で紹介されたナインティナイン矢部浩之の高校卒業文集がネット掲示板で話題を呼んでいる。\n",
      "\n",
      "番組内で紹介された矢部の文集は「どうもこんにちは。99(ナインティナイン)です」という一文から始まり、「2丁目劇場をしきって、ダウンタウンの位置をいただきます」「東京に進出して、とんねるずの位置をいただきます」「エレベーター式にたけしの位置をいただくと同時に、欽ちゃんはその時点でおびえています」など、超大物芸人を引き合いに出したビッグマウス発言がズラリ。\n",
      "\n",
      "これを受け、ネット掲示板では「センスあるな 」「これはすごい予言 」など、矢部を賞賛する声が相次ぐ一方で、「矢部が学生時代のころからお笑い界の上のやつらがあまり変わってない」など、新陳代謝が停滞するお笑い界への指摘の声も見られた。\n",
      "\n",
      "矢部の卒業文集は「私たち99がお笑い界の帝王となるのです」という一文で締め括られていたが、現実となる日は来るのだろうか?\n",
      "\n",
      "・1番ソングSHOW - 日本テレビ\n",
      "・ 【画像あり】矢部浩之の卒業文集クソワロタｗｗｗｗｗｗ - 暇人速報\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "## indices は 0〜7366 の整数をランダムに並べ替えた配列\n",
    "random.seed()\n",
    "indices = list(range(len(docs)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_data   = [docs[i] for i in indices[0:7000]]\n",
    "train_labels = [labels[i] for i in indices[0:7000]]\n",
    "test_data    = [docs[i] for i in indices[7000:]]\n",
    "test_labels  = [labels[i] for i in indices[7000:]]\n",
    "print (train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 33971)\t0.0519735806234\n",
      "  (0, 23042)\t0.0823904808449\n",
      "  (0, 159)\t0.052044608846\n",
      "  (0, 27520)\t0.0408084942445\n",
      "  (0, 23668)\t0.0377505141075\n",
      "  (0, 27102)\t0.0448381917215\n",
      "  (0, 29981)\t0.083657913074\n",
      "  (0, 2595)\t0.0269073063243\n",
      "  (0, 2510)\t0.0246848490647\n",
      "  (0, 19106)\t0.0867535840959\n",
      "  (0, 1955)\t0.0263784044782\n",
      "  (0, 28808)\t0.0287060294693\n",
      "  (0, 3688)\t0.0194199073984\n",
      "  (0, 32098)\t0.0210415141326\n",
      "  (0, 21614)\t0.0489667683777\n",
      "  (0, 12610)\t0.0911166873469\n",
      "  (0, 22497)\t0.0743499034422\n",
      "  (0, 2254)\t0.0275194541838\n",
      "  (0, 16735)\t0.0341028894525\n",
      "  (0, 3679)\t0.038193722577\n",
      "  (0, 3531)\t0.0614510541772\n",
      "  (0, 27534)\t0.126941069817\n",
      "  (0, 752)\t0.171093497713\n",
      "  (0, 1338)\t0.0607886459016\n",
      "  (0, 22947)\t0.0337327047591\n",
      "  :\t:\n",
      "  (0, 10453)\t0.0687403645281\n",
      "  (0, 17548)\t0.0407584442163\n",
      "  (0, 10315)\t0.158589619646\n",
      "  (0, 13218)\t0.0326458358119\n",
      "  (0, 27579)\t0.0343615407366\n",
      "  (0, 329)\t0.0339135686042\n",
      "  (0, 15729)\t0.0361241511187\n",
      "  (0, 21847)\t0.073656751562\n",
      "  (0, 36356)\t0.0503960192449\n",
      "  (0, 3713)\t0.0362828147981\n",
      "  (0, 1770)\t0.0539421939762\n",
      "  (0, 29661)\t0.0522638302074\n",
      "  (0, 6616)\t0.127875973089\n",
      "  (0, 27568)\t0.0975094545941\n",
      "  (0, 22618)\t0.0966855655375\n",
      "  (0, 22560)\t0.0294214528667\n",
      "  (0, 23253)\t0.0180472134823\n",
      "  (0, 32589)\t0.0493531956583\n",
      "  (0, 10596)\t0.0504919201608\n",
      "  (0, 7482)\t0.0849894767263\n",
      "  (0, 22346)\t0.492877308099\n",
      "  (0, 14537)\t0.202573613585\n",
      "  (0, 25628)\t0.237884429469\n",
      "  (0, 28373)\t0.538255345818\n",
      "  (0, 7331)\t0.142793521635\n"
     ]
    }
   ],
   "source": [
    "from natto import MeCab\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = []\n",
    "    with MeCab('-F%f[0],%f[6]') as nm:\n",
    "        for n in nm.parse(text, as_nodes=True):\n",
    "            # ignore any end-of-sentence nodes\n",
    "            if not n.is_eos() and n.is_nor():\n",
    "                klass, word = n.feature.split(',', 1)\n",
    "                if klass in ['名詞', '形容詞', '形容動詞', '動詞']:\n",
    "                    tokens.append(word)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize)\n",
    "train_matrix = vectorizer.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.882714285714\n",
      "0.839237057221\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_matrix, train_labels)\n",
    "\n",
    "test_matrix = vectorizer.transform(test_data)\n",
    "print(clf.score(train_matrix, train_labels)) # 0.881\n",
    "print(clf.score(test_matrix, test_labels)) # 0.825613079019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump(clf, open(\"model_origin.pkl\", \"wb\")) #モデル保存\n",
    "# #clf = pickle.load(open(\"model.pkl\", \"rb\")) 　#モデル読み込み　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['本日のテーマMicrosoftFlow#MicrosoftFlowJapanSharePointGroup\\n   本日のゴールMicrosoftFlowというサービスを知ってもらうなにができそうかを知ってもらう\\n   JapanSharePointGroupMicrosoftFlowというサービスを知ってもらうなにができそうかを知ってもらう\\n   JapanSharePointGroupSharePointGroup']\n",
      "  (0, 0)\t0.272165526976\n",
      "  (0, 1)\t0.272165526976\n",
      "  (0, 2)\t0.272165526976\n",
      "  (0, 3)\t0.544331053952\n",
      "  (0, 8)\t0.544331053952\n",
      "  (0, 5)\t0.272165526976\n",
      "  (0, 4)\t0.136082763488\n",
      "  (0, 6)\t0.136082763488\n",
      "  (0, 7)\t0.272165526976\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-d9274512105d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_data_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_matrix_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_matrix_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/hikaru/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \"\"\"\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hikaru/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         return (safe_sparse_dot(X, self.feature_log_prob_.T)\n\u001b[0m\u001b[1;32m    673\u001b[0m                 + self.class_log_prior_)\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hikaru/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \"\"\"\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdense_output\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"toarray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hikaru/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_multivector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: dimension mismatch"
     ]
    }
   ],
   "source": [
    "test_data_real = [\n",
    "   \"\"\"本日のテーマMicrosoftFlow#MicrosoftFlowJapanSharePointGroup\n",
    "   本日のゴールMicrosoftFlowというサービスを知ってもらうなにができそうかを知ってもらう\n",
    "   JapanSharePointGroupMicrosoftFlowというサービスを知ってもらうなにができそうかを知ってもらう\n",
    "   JapanSharePointGroupSharePointGroup\"\"\"\"\"\n",
    "]\n",
    "\n",
    "test_matrix_real = vectorizer.fit_transform(test_data_real)\n",
    "print (test_data_real)\n",
    "print (test_matrix_real)\n",
    "print(clf.predict(test_matrix_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
